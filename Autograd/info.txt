loss function:
mesures how well the NN prediction match the actual output.
goal is to minimize loss function

loss function methods:
mean squared error, for regression
cross entroy loss, for classification
------------------------------------------------------------

gradient:

is a vector. points in direction of steepest increase of the loss function.
tells how loss function changes w.r.t to changes in networks parameters

Backpropagation: is the process of calculating the gradient of the loss function
wrt to network parameters

the gradient tells how much to change each parameters, by moving them in opposite direction 
of the gradient


so in the gpaph
y axis is the loss function, x axis is the iterations/epochs

and the ultimate goal is to converge at a min point, by taking small steps (Backpropagation)
but consider there can be local minima and global minimum. we dont know which one we hit

----------------------------------------------------------------------

micrograd:
autograd with Backpropagation
 
